{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrwinrao/WOA7015/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction\n",
        "Read the following text and perform the following code. Every code is self-explainatory."
      ],
      "metadata": {
        "id": "teww6eLMd-Zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression\n",
        "\n",
        "is an approach that tries to find a linear relationship between a dependent variable and an independent variable by minimizing the distance as shown below.\n",
        "\n",
        "In this colab, we will learn how to implement a simple linear regression model using PyTorch.\n",
        "\n",
        "Let’s consider a very basic linear equation i.e., y=2x+1. Here, ‘x’ is the independent variable and y is the dependent variable. We’ll use this equation to create a dummy dataset which will be used to train this linear regression model. Following is the code for creating the dataset."
      ],
      "metadata": {
        "id": "Uw8QfCiI28sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# create dummy data for training\n",
        "x_values = [i for i in range(11)]\n",
        "x_train = np.array(x_values, dtype=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "\n",
        "y_values = [2*i + 1 for i in x_values]\n",
        "y_train = np.array(y_values, dtype=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "plyJbABU3LLo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have created the dataset, we can start writing the code for our model. First thing will be to define the model architecture. We do that using the following piece of code."
      ],
      "metadata": {
        "id": "saEfyiM43Kr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "H8G8dA5u3NWS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We defined a class for linear regression, that inherits torch.nn.Module which is the basic Neural Network module containing all the required functions. Our Linear Regression model only contains one simple linear function.\n",
        "\n",
        "Next, we instantiate the model using the following code."
      ],
      "metadata": {
        "id": "cv8E4ORN3PKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_feature_size = 1       # takes variable 'x' - 1 features\n",
        "out_feature_size= 1       # takes variable 'y'\n",
        "learningRate = 0.01\n",
        "epochs = 100\n",
        "\n",
        "model = linearRegression(in_feature_size, out_feature_size)\n",
        "##### For GPU #######\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "8jb4Hk1C3Qle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we initialize the loss (Mean Squared Error) and optimization (Adam) functions that we’ll use in the training of this model."
      ],
      "metadata": {
        "id": "NnIq2K3s3PPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)"
      ],
      "metadata": {
        "id": "2ZYdJuZX3S6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After completing all the initializations, we can now begin to train our model. Following is the code for training the model."
      ],
      "metadata": {
        "id": "ukTs1n8v3UGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Converting inputs and labels to Variable\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
        "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
        "    else:\n",
        "        inputs = Variable(torch.from_numpy(x_train))\n",
        "        labels = Variable(torch.from_numpy(y_train))\n",
        "\n",
        "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get output from the model, given the inputs\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # get loss for the predicted output\n",
        "    loss = criterion(outputs, labels)\n",
        "    # get gradients w.r.t to parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "    training_loss.append(loss.item())"
      ],
      "metadata": {
        "id": "Fh_ngRxc3VY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the loss curve"
      ],
      "metadata": {
        "id": "_hFeNxZNI9kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(np.arange(epochs), training_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('training loss')"
      ],
      "metadata": {
        "id": "gcdlkKgyI_6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our Linear Regression Model is trained, let’s test it. Since it’s a very trivial model, we’ll test this on our existing dataset and also plot to see the original vs the predicted outputs."
      ],
      "metadata": {
        "id": "b7HizLNp3WnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "    if torch.cuda.is_available():\n",
        "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
        "    else:\n",
        "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
        "    print(predicted)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
        "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pOVuaOql3Xy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to infer y when x = 7\n",
        "\n",
        "x_infer = np.array([7], dtype=np.float32)\n",
        "x_infer = x_infer.reshape(-1, 1)\n",
        "\n",
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "    if torch.cuda.is_available():\n",
        "        predicted = model(Variable(torch.from_numpy(x_infer).cuda())).cpu().data.numpy()\n",
        "    else:\n",
        "        predicted = model(Variable(torch.from_numpy(x_infer))).data.numpy()\n",
        "    print('when x = 7, y = ', predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGuIEXQMOg6j",
        "outputId": "587219dd-c020-4059-cfa5-d6cfb9121f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when x = 7, y =  [[15.010226]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the weight\n",
        "\n",
        "for param in model.parameters():\n",
        "  print(param.data)"
      ],
      "metadata": {
        "id": "k5np4uBqKWoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check\n",
        "1. Are the weight obtained are m = 2, c = 1?\n",
        "2. If no, this means that your model have not finish training, you can also check from the loss curve above, does the loss still going down?\n",
        "3. If the error is still going now, try using larger epoch (train longer). Check the model.parameters.\n",
        "4. You should be able to get the model parameters of [2, 1] when you use epoch = 1000."
      ],
      "metadata": {
        "id": "Z5mh8FezeRVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our model has correctly figured out the linear relation between our dependent and independent variables.\n",
        "\n",
        "If you have understood this, you should try and train a linear regression model for a little more complex linear equation with multiple independent variables."
      ],
      "metadata": {
        "id": "2eGZVMRs3ZwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reference\n",
        "\n",
        "Credit to Asad Mahmood.\n",
        "https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817"
      ],
      "metadata": {
        "id": "jnwY2Atj3aXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now  is your turn.\n",
        "\n",
        "Create a linear regression model using the following data.\n",
        "\n",
        "\n",
        "Observe the loss value and compare the weight obtained with the true weight [0.052, 29.21]"
      ],
      "metadata": {
        "id": "DLkZJOh4JYKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = [i for i in range(30)]\n",
        "x = np.array(x_values, dtype=np.float32)\n",
        "x = x.reshape(-1, 1)\n",
        "\n",
        "y_values = [0.052*i + 29.21  for i in x_values] + np.random.normal(0,0.1,30)\n",
        "y = np.array(y_values, dtype=np.float32)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "plt.plot(x, y, '.')"
      ],
      "metadata": {
        "id": "4pLkpPeqJtZq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "f54b41fe-4941-4715-82ce-d64ef5877835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d5856a8a0e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGdCAYAAAA1/PiZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA12ElEQVR4nO3df1DU953H8deCsiKwiwgKHCIYK2iVtHpUt/ZIogTj9IwBbUiba/Quk4w5tBGbnGLH/rhrXJv0mrNJY+5yHZO7lGhNpYl2jKYSsBr0FONF84MknAYvLlCauBhAZNjv/WHZ6zagLKDf/S7Px8x3Rr77/X72/f3Od7KvfD+f7+drMwzDEAAAgAVEmF0AAABAfxFcAACAZRBcAACAZRBcAACAZRBcAACAZRBcAACAZRBcAACAZRBcAACAZYwwu4Ch4vP5dO7cOcXFxclms5ldDgAA6AfDMHThwgWlpqYqIuLq91PCJricO3dOEyZMMLsMAAAwAGfPnlVaWtpVtwub4BIXFyfp8oE7HA6TqwEAAP3R2tqqCRMm+H/HryZsgktP95DD4SC4AABgMf0d5sHgXAAAYBlBBZctW7YoJyfHf1fD5XJpz549/s8vXryokpISjR07VrGxsVqyZImampqu2Oann36qlStXKi0tTdHR0Zo2bZqefvrpgR0NAAAIa0EFl7S0NG3atEm1tbU6duyY5s2bp8WLF+utt96SJJWWlmrXrl3asWOHqqurde7cORUVFV2xzTVr1uiVV17R888/r3feeUerV6/WypUr9fLLLw/8qAAAQFiyGYZhDKaBhIQEPfbYY1q6dKmSkpJUXl6upUuXSpLeffddTZ06VTU1NZozZ06v+0+fPl3FxcXasGGDf92sWbO0cOFC/fCHP+x3Ha2trXI6nfJ6vYxxAQDAIoL9/R7wGJfu7m5t27ZNbW1tcrlcqq2tVVdXl/Lz8/3bZGdnKz09XTU1NX228+Uvf1kvv/yyPvroIxmGoddee03vvfeeCgoKrvj9nZ2dam1tDVgAAEB4Czq4nDx5UrGxsbLb7VqxYoUqKio0bdo0NTY2KioqSvHx8QHbjx8/Xo2NjX2298QTT2jatGlKS0tTVFSUbrvtNv3sZz9TXl7eFetwu91yOp3+hTlcAAAIf0E/Dp2VlaUTJ07I6/XqxRdf1LJly1RdXT3gAp544gkdPnxYL7/8siZOnKgDBw6opKREqampAXdv/lxZWZnWrFnj/7vnOXAAABC+gg4uUVFRmjx5sqTLY1GOHj2qzZs3q7i4WJcuXdL58+cD7ro0NTUpOTm517Y6Ojq0fv16VVRU6Ktf/aokKScnRydOnNCPf/zjKwYXu90uu90ebPkAAMDCBj2Pi8/nU2dnp2bNmqWRI0dq//79/s/q6urU0NAgl8vV675dXV3q6ur6zLsJIiMj5fP5BlsaAAAIM0HdcSkrK9PChQuVnp6uCxcuqLy8XFVVVdq7d6+cTqfuvfderVmzRgkJCXI4HFq1apVcLlfAE0XZ2dlyu90qLCyUw+HQTTfdpIcffljR0dGaOHGiqqur9R//8R/6yU9+MuQHCwAArC2o4NLc3Kx77rlHHo9HTqdTOTk52rt3r2699VZJ0uOPP66IiAgtWbJEnZ2dWrBggZ566qmANurq6uT1ev1/b9u2TWVlZbr77rv18ccfa+LEiXrkkUe0YsWKITg8AAAwWB5vh063tCkzMUYpzmhTaxn0PC6hgnlcAAAYetuPNqhs50n5DCnCJrmLZqg4N33I2r9u87gAAIDw5vF2+EOLJPkMaf3OU/J4O0yrieACAAB6dbqlzR9aenQbhs60tJtTkAguAACgD5mJMYqwBa6LtNmUkTjanIJEcAEAAH1IcUbLXTRDkbbL6SXSZtPGoummDtANegI6AAAwfBTnpitvSpLOtLQrI3G06U8VEVwAAMAVpTijTQ8sPegqAgAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQDAAjzeDr1e3yKPt8PsUkw1wuwCAADAlW0/2qCynSflM6QIm+QumqHi3HSzyzJFUHdctmzZopycHDkcDjkcDrlcLu3Zs8f/+cWLF1VSUqKxY8cqNjZWS5YsUVNT01Xbfeedd3T77bfL6XQqJiZGubm5amhoCP5oAAAIMx5vhz+0SJLPkNbvPDVs77wEFVzS0tK0adMm1dbW6tixY5o3b54WL16st956S5JUWlqqXbt2aceOHaqurta5c+dUVFR0xTbr6+v1la98RdnZ2aqqqtKbb76pDRs2aNSoUQM/KgAAwsTpljZ/aOnRbRg609JuTkEmsxmGYVx9s74lJCToscce09KlS5WUlKTy8nItXbpUkvTuu+9q6tSpqqmp0Zw5c3rd/6677tLIkSP1n//5n4MpQ62trXI6nfJ6vXI4HINqCwCAUOHxdmjupsqA8BJps+nguluU4owOqp3TLW3KTIwJar9rLdjf7wEPzu3u7ta2bdvU1tYml8ul2tpadXV1KT8/379Ndna20tPTVVNT02sbPp9Pv/nNbzRlyhQtWLBA48aN0+zZs/XrX//6qt/f2dmp1tbWgAUAgHCT4oyWu2iGIm02SZdDy8ai6UGFj+1HGzR3U6W+8cwRzd1Uqe1HrTscI+jgcvLkScXGxsput2vFihWqqKjQtGnT1NjYqKioKMXHxwdsP378eDU2NvbaVnNzsz799FNt2rRJt912m/bt26fCwkIVFRWpurr6inW43W45nU7/MmHChGAPBQAASyjOTdfBdbfohfvm6OC6W4IamBtuY2SCfqooKytLJ06ckNfr1Ysvvqhly5ZdNWT0xefzSZIWL16s0tJSSdIXvvAFvf7663r66ad100039blvWVmZ1qxZ4/+7tbWV8AIACFspzugBdfFcaYxMKHUZ9VfQwSUqKkqTJ0+WJM2aNUtHjx7V5s2bVVxcrEuXLun8+fMBd12ampqUnJzca1uJiYkaMWKEpk2bFrB+6tSpOnjw4BXrsNvtstvtwZYPAMCwkpkYowibPjNGJiNxtHlFDcKgJ6Dz+Xzq7OzUrFmzNHLkSO3fv9//WV1dnRoaGuRyuXrdNyoqSrm5uaqrqwtY/95772nixImDLQ0AgGFvKMbIhJKg7riUlZVp4cKFSk9P14ULF1ReXq6qqirt3btXTqdT9957r9asWaOEhAQ5HA6tWrVKLpcr4Imi7Oxsud1uFRYWSpIefvhhFRcXKy8vT7fccoteeeUV7dq1S1VVVUN6oAAADFfFuenKm5KkMy3tykgcbdnQIgUZXJqbm3XPPffI4/HI6XQqJydHe/fu1a233ipJevzxxxUREaElS5aos7NTCxYs0FNPPRXQRl1dnbxer//vwsJCPf3003K73frWt76lrKws/epXv9JXvvKVITg8AAAgDXyMTKgZ9DwuoYJ5XAAAsJ7rNo8LAADA9UZwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQCgnzzeDr1e3yKPt8PsUoatoN8ODQDAcLT9aIPKdp6Uz5AibJK7aIaKc9PNLmvY4Y4LAABX4fF2+EOLJPkMaf3OU9x5MQHBBQCAqzjd0uYPLT26DUNnWtrNKWgYI7gAAHAVmYkxirAFrou02ZSRONqcgoYxggsAYNgY6ODaFGe03EUzFGm7nF4ibTZtLJquFGf0tSgTV8DgXADAsDDYwbXFuenKm5KkMy3tykgcHXRo8Xg7dLqlTZmJMQSeQSC4AADCXl+Da/OmJAUVIlKc0QMKHTyRNHToKgIAhD0zB9fyRNLQIrgAAMKemYNreSJpaBFcAABhz8zBtTyRNLQY4wIAGBYGO7h2oHpC0/qdp9RtGDyRNEgEFwDAsDHQwbWDZVZoCkcEFwAArgOzQlO4YYwLAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwjKCCy5YtW5STkyOHwyGHwyGXy6U9e/b4P7948aJKSko0duxYxcbGasmSJWpqaup3+ytWrJDNZtO//Mu/BFMWAAAYJoIKLmlpadq0aZNqa2t17NgxzZs3T4sXL9Zbb70lSSotLdWuXbu0Y8cOVVdX69y5cyoqKupX2xUVFTp8+LBSU1ODPwoAADAsBPWSxUWLFgX8/cgjj2jLli06fPiw0tLS9POf/1zl5eWaN2+eJGnr1q2aOnWqDh8+rDlz5vTZ7kcffaRVq1Zp7969+upXvzqAwwAAAMPBgMe4dHd3a9u2bWpra5PL5VJtba26urqUn5/v3yY7O1vp6emqqanpsx2fz6dvfvObevjhh/X5z3++39/f2dmp1tbWgAUAAIS3oIPLyZMnFRsbK7vdrhUrVqiiokLTpk1TY2OjoqKiFB8fH7D9+PHj1djY2Gd7P/rRjzRixAh961vfCqoOt9stp9PpXyZMmBDsoQAATODxduj1+hZ5vB1mlwILCqqrSJKysrJ04sQJeb1evfjii1q2bJmqq6sH9OW1tbXavHmzjh8/LpvNFtS+ZWVlWrNmjf/v1tZWwgsAhLjtRxtUtvOkfIYUYZPcRTNUnJtudlmwkKDvuERFRWny5MmaNWuW3G63brzxRm3evFnJycm6dOmSzp8/H7B9U1OTkpOTe23rd7/7nZqbm5Wenq4RI0ZoxIgR+vDDD/Xtb39bGRkZV6zDbrf7n27qWQAAocvj7fCHFknyGdL6nae484KgDHoeF5/Pp87OTs2aNUsjR47U/v37/Z/V1dWpoaFBLper132/+c1v6s0339SJEyf8S2pqqh5++GHt3bt3sKUBAELI6ZY2f2jp0W0YOtPSHlQ7dDUNb0F1FZWVlWnhwoVKT0/XhQsXVF5erqqqKu3du1dOp1P33nuv1qxZo4SEBDkcDq1atUoulyvgiaLs7Gy53W4VFhZq7NixGjt2bMB3jBw5UsnJycrKyhqaIwQAhITMxBhF2BQQXiJtNmUkju53G3Q1Iajg0tzcrHvuuUcej0dOp1M5OTnau3evbr31VknS448/roiICC1ZskSdnZ1asGCBnnrqqYA26urq5PV6h+4IAACWkOKMlrtohtbvPKVuw1CkzaaNRdOV4ozu1/59dTXlTUnqdxuwPpthGMbVNwt9ra2tcjqd8nq9jHcBgBDm8XboTEu7MhJHBxU4Xq9v0TeeOfKZ9S/cN0euG8b2sgesINjf76CfKgIAYDBSnNEDukMyFF1NsD5esggAsISerqbIP06fEWxXE8IDd1wAAJZRnJuuvClJA+pqQngguAAALGWgXU0ID3QVAQAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AIBJPN4OvV7fIo+3w+xSAMtgyn8AMMH2ow0q23lSPkOKsEnuohkqzk03uywg5HHHBQCuM4+3wx9aJMlnSOt3nuLOC9APBBcAuM5Ot7T5Q0uPbsPQmZZ2cwoCLITgAgDXWWZijCJsgesibTZlJI42pyDAQgguAHCdpTij5S6aoUjb5fQSabNpY9F0pTijTa4MCH0MzgUAExTnpitvSpLOtLQrI3E0oQXoJ4ILAJgkxRlNYAGCRFcRAACwDIILAACwDIILAACwDIILACBovK4AZmFwLgAgKLyuAGbijgsAoN94XQHMRnABAPQbryuA2QguAIB+43UFMBvBBQDQb7yuAGZjcC4AICi8rgBmIrgAAILG6wpglqC6irZs2aKcnBw5HA45HA65XC7t2bPH//nFixdVUlKisWPHKjY2VkuWLFFTU1Of7XV1dWnt2rWaMWOGYmJilJqaqnvuuUfnzp0b+BEBAICwFVRwSUtL06ZNm1RbW6tjx45p3rx5Wrx4sd566y1JUmlpqXbt2qUdO3aourpa586dU1FRUZ/ttbe36/jx49qwYYOOHz+unTt3qq6uTrfffvvgjgoAAIQlm2EYxtU361tCQoIee+wxLV26VElJSSovL9fSpUslSe+++66mTp2qmpoazZkzp1/tHT16VF/60pf04YcfKj29/xMatba2yul0yuv1yuFwDOhYACAYHm+HTre0KTMxhm4TYICC/f0e8BiX7u5u7dixQ21tbXK5XKqtrVVXV5fy8/P922RnZys9PT2o4OL1emWz2RQfH3/F7To7O9XZ2en/u7W1dUDHAQADweyxgDmCfhz65MmTio2Nld1u14oVK1RRUaFp06apsbFRUVFRnwkc48ePV2NjY7/avnjxotauXauvf/3rV01dbrdbTqfTv0yYMCHYQwGAAWH2WMA8QQeXrKwsnThxQkeOHNEDDzygZcuW6e233x50IV1dXbrzzjtlGIa2bNly1e3Lysrk9Xr9y9mzZwddAwD0B7PHAuYJuqsoKipKkydPliTNmjVLR48e1ebNm1VcXKxLly7p/PnzAXddmpqalJycfMU2e0LLhx9+qMrKyn71cdntdtnt9mDLB4BB65k99k/DC7PHAtfHoGfO9fl86uzs1KxZszRy5Ejt37/f/1ldXZ0aGhrkcrn63L8ntLz//vv67W9/q7Fjxw62JAC4pkJl9liPt0Ov17fQRYVhJag7LmVlZVq4cKHS09N14cIFlZeXq6qqSnv37pXT6dS9996rNWvWKCEhQQ6HQ6tWrZLL5QoYmJudnS23263CwkJ1dXVp6dKlOn78uHbv3q3u7m7/eJiEhARFRUUN7dECwBAxe/ZYBgdjuAoquDQ3N+uee+6Rx+OR0+lUTk6O9u7dq1tvvVWS9PjjjysiIkJLlixRZ2enFixYoKeeeiqgjbq6Onm9XknSRx99pJdfflmS9IUvfCFgu9dee00333zzAA8LAK49s2aP7WtwcN6UJB7LRtgb9DwuoYJ5XAAMF6/Xt+gbzxz5zPoX7psj1w10t8Nagv395u3QAGAxPYOD/xSDgzFcEFwAwGJCZXAwYAbeDg0AFmT24GDALAQXALAoswYHA2aiqwgAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAhiGPt0Ov17fI4+0wuxQgKCPMLgAAcH1tP9qgsp0n5TOkCJvkLpqh4tx0s8sC+oU7LgAwjHi8Hf7QIkk+Q1q/8xR3XmAZBBcAw9pw6zI53dLmDy09ug1DZ1razSkICBJdRQCGreHYZZKZGKMImwLCS6TNpozE0eYVBQSBOy4AhqXh2mWS4oyWu2iGIm02SZdDy8ai6UpxRptcGdA/3HEBMCxdqcsk3H/Ei3PTlTclSWda2pWRODrsjxfhheACYFga7l0mKc5oAgssia4iAMMSXSaANXHHBcCwRZcJYD0EFwDDGl0mgLUE1VW0ZcsW5eTkyOFwyOFwyOVyac+ePf7PL168qJKSEo0dO1axsbFasmSJmpqartimYRj67ne/q5SUFEVHRys/P1/vv//+wI4GwLAz3OZhAYa7oIJLWlqaNm3apNraWh07dkzz5s3T4sWL9dZbb0mSSktLtWvXLu3YsUPV1dU6d+6cioqKrtjmo48+qp/+9Kd6+umndeTIEcXExGjBggW6ePHiwI8KwLCw/WiD5m6q1DeeOaK5myq1/WiD2SUBuMZshmEYV9+sbwkJCXrssce0dOlSJSUlqby8XEuXLpUkvfvuu5o6dapqamo0Z86cz+xrGIZSU1P17W9/Ww899JAkyev1avz48Xr22Wd111139buO1tZWOZ1Oeb1eORyOwRwSAAvweDs0d1PlZ54KOrjuFrp+AAsJ9vd7wE8VdXd3a9u2bWpra5PL5VJtba26urqUn5/v3yY7O1vp6emqqanptY3Tp0+rsbExYB+n06nZs2f3uU+Pzs5Otba2BiwAhg+mrgeGp6CDy8mTJxUbGyu73a4VK1aooqJC06ZNU2Njo6KiohQfHx+w/fjx49XY2NhrWz3rx48f3+99erjdbjmdTv8yYcKEYA8FgIX1zMPyp4bTPCzAcBV0cMnKytKJEyd05MgRPfDAA1q2bJnefvvta1HbFZWVlcnr9fqXs2fPXvcaAJiHeViA4Snox6GjoqI0efJkSdKsWbN09OhRbd68WcXFxbp06ZLOnz8fcNelqalJycnJvbbVs76pqUkpKSkB+3zhC1+4Yh12u112uz3Y8gGEEeZhAYafQc+c6/P51NnZqVmzZmnkyJHav3+//7O6ujo1NDTI5XL1um9mZqaSk5MD9mltbdWRI0f63AcA/lSKM1quG8YSWoBhIqg7LmVlZVq4cKHS09N14cIFlZeXq6qqSnv37pXT6dS9996rNWvWKCEhQQ6HQ6tWrZLL5Qp4oig7O1tut1uFhYWy2WxavXq1fvjDH+pzn/ucMjMztWHDBqWmpuqOO+4Y6mMFAAAWF1RwaW5u1j333COPxyOn06mcnBzt3btXt956qyTp8ccfV0REhJYsWaLOzk4tWLBATz31VEAbdXV18nq9/r//4R/+QW1tbbr//vt1/vx5feUrX9Err7yiUaNGDcHhAQCAcDLoeVxCBfO4AABgPddtHhcAAIDrjeACAAAsg+ACAAAsg+ACAAAsg+ACAAAsg+ACQNLlty2/Xt8ij7fD7FIAoE9BT/kPIPxsP9qgsp0n5TOkCJvkLpqh4tx0s8sCgM/gjgswzHm8Hf7QIkk+Q1q/8xR3XgCEJIILMMydbmnzh5Ye3YahMy3t5hQEAFdAcAGGuczEGEXYAtdF2mzKSBxtTkEAcAUEF2CYS3FGy100Q5G2y+kl0mbTxqLpvG0ZQEhicC4AFeemK29Kks60tCsjcTShBUDIIrgAkHT5zguBBUCoo6sIAABYBsEFgOmY/A5Af9FVBMBUTH4HIBjccQFgGia/AxAsggsA0zD5HYBgEVwAmIbJ7wAEi+ACwDRMfgcgWAzOBWAqJr8DEAyCCwDTMfkdgP6iqwgAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFgGwQUAAFhGUMHF7XYrNzdXcXFxGjdunO644w7V1dUFbFNfX6/CwkIlJSXJ4XDozjvvVFNT0xXb7e7u1oYNG5SZmano6GjdcMMN+qd/+icZhnHF/QAAwPASVHCprq5WSUmJDh8+rFdffVVdXV0qKChQW1ubJKmtrU0FBQWy2WyqrKzUoUOHdOnSJS1atEg+n6/Pdn/0ox9py5YtevLJJ/XOO+/oRz/6kR599FE98cQTgzs6AAAQVmzGIG5r/P73v9e4ceNUXV2tvLw87du3TwsXLtQnn3wih8MhSfJ6vRozZoz27dun/Pz8Xtv567/+a40fP14///nP/euWLFmi6OhoPf/88/2qpbW1VU6nU16v1//dAAAgtAX7+z2oMS5er1eSlJCQIEnq7OyUzWaT3W73bzNq1ChFRETo4MGDfbbz5S9/Wfv379d7770nSfrv//5vHTx4UAsXLuxzn87OTrW2tgYsgNk83g69Xt8ij7fD7FIAICyNGOiOPp9Pq1ev1ty5czV9+nRJ0pw5cxQTE6O1a9dq48aNMgxD69atU3d3tzweT59trVu3Tq2trcrOzlZkZKS6u7v1yCOP6O677+5zH7fbrR/84AcDLR8YctuPNqhs50n5DCnCJrmLZqg4N93ssgAgrAz4jktJSYlOnTqlbdu2+dclJSVpx44d2rVrl2JjY+V0OnX+/HnNnDlTERF9f9Uvf/lL/eIXv1B5ebmOHz+u5557Tj/+8Y/13HPP9blPWVmZvF6vfzl79uxADwUYNI+3wx9aJMlnSOt3nuLOCwAMsQHdcVm5cqV2796tAwcOKC0tLeCzgoIC1dfXq6WlRSNGjFB8fLySk5M1adKkPtt7+OGHtW7dOt11112SpBkzZujDDz+U2+3WsmXLet3HbrcHdEkBZjrd0uYPLT26DUNnWtqV4ow2pygACENBBRfDMLRq1SpVVFSoqqpKmZmZfW6bmJgoSaqsrFRzc7Nuv/32Prdtb2//zB2ZyMjIKz6JBISSzMQYRdgUEF4ibTZlJI42rygACENBdRWVlJTo+eefV3l5ueLi4tTY2KjGxkZ1dPz/7fCtW7fq8OHDqq+v1/PPP6+vfe1rKi0tVVZWln+b+fPn68knn/T/vWjRIj3yyCP6zW9+ozNnzqiiokI/+clPVFhYOASHCFx7Kc5ouYtmKNJmk3Q5tGwsms7dFgAYYkE9Dm3743+U/9zWrVu1fPlySZcH2j777LP6+OOPlZGRoRUrVqi0tDRg34yMDC1fvlzf//73JUkXLlzQhg0bVFFRoebmZqWmpurrX/+6vvvd7yoqKqpftfE4NEKBx9uhMy3tykgcTWgBgH4I9vd7UPO4hBKCCwAA1nNd53EBAAC4ngguAADAMgguAADAMgguAADAMgguAADAMgguAADAMgguAADAMgguAADAMgguAADAMgguQJjweDv0en2LPN6Oq28MABYV1NuhAYSm7UcbVLbzpHyGFGGT3EUzVJybbnZZADDkuOMCWJzH2+EPLZLkM6T1O09x5wVAWCK4ABZ3uqXNH1p6dBuGzrS0m1MQAFxDBBfA4jITYxRhC1wXabMpI3G0OQUBwDVEcAEsLsUZLXfRDEXaLqeXSJtNG4umK8UZbXJlADD0GJwLhIHi3HTlTUnSmZZ2ZSSOJrQACFsEFyBMpDijCSwAwh5dRQAAwDIILgAAwDIILgAAwDIILgAAwDIILgAAwDIILgAAwDIILgAAwDIILgAGzePt0Ov1LbzYEcA1xwR0AAZl+9EG/9upI2ySu2iGinPTzS4LQJjijguAAfN4O/yhRZJ8hrR+5ynuvAC4ZgguQAixWpfL6ZY2f2jp0W0YOtPSbk5BAMIeXUVAiLBil0tmYowibAoIL5E2mzISR5tXFICwxh0XIARYtcslxRktd9EMRdpski6Hlo1F03nZI4BrhjsuQAi4UpdLqIeA4tx05U1J0pmWdmUkjg75egFYG8EFCAFW73JJcUYTWABcF0F1FbndbuXm5iouLk7jxo3THXfcobq6uoBt6uvrVVhYqKSkJDkcDt15551qamq6atsfffSR/uZv/kZjx45VdHS0ZsyYoWPHjgV3NIBF0eUCAP0TVHCprq5WSUmJDh8+rFdffVVdXV0qKChQW1ubJKmtrU0FBQWy2WyqrKzUoUOHdOnSJS1atEg+n6/Pdj/55BPNnTtXI0eO1J49e/T222/rn//5nzVmzJjBHR1gIcW56Tq47ha9cN8cHVx3S8gPzAUAM9gMwzCuvlnvfv/732vcuHGqrq5WXl6e9u3bp4ULF+qTTz6Rw+GQJHm9Xo0ZM0b79u1Tfn5+r+2sW7dOhw4d0u9+97uBlqLW1lY5nU55vV7/dwMAgNAW7O/3oJ4q8nq9kqSEhARJUmdnp2w2m+x2u3+bUaNGKSIiQgcPHuyznZdffll/+Zd/qa997WsaN26cvvjFL+qZZ5654nd3dnaqtbU1YEF4sNpcJgCA62fAwcXn82n16tWaO3eupk+fLkmaM2eOYmJitHbtWrW3t6utrU0PPfSQuru75fF4+mzrf/7nf7RlyxZ97nOf0969e/XAAw/oW9/6lp577rk+93G73XI6nf5lwoQJAz0UhJDtRxs0d1OlvvHMEc3dVKntRxvMLgkAEEIGHFxKSkp06tQpbdu2zb8uKSlJO3bs0K5duxQbGyun06nz589r5syZiojo+6t8Pp9mzpypjRs36otf/KLuv/9+3XfffXr66af73KesrExer9e/nD17dqCHghBh1blMAADXz4Aeh165cqV2796tAwcOKC0tLeCzgoIC1dfXq6WlRSNGjFB8fLySk5M1adKkPttLSUnRtGnTAtZNnTpVv/rVr/rcx263B3RJwfqsPJcJAOD6CCq4GIahVatWqaKiQlVVVcrMzOxz28TERElSZWWlmpubdfvtt/e57dy5cz/zWPV7772niRMnBlMeLM7qc5kAAK69oLqKSkpK9Pzzz6u8vFxxcXFqbGxUY2OjOjr+/1b+1q1bdfjwYdXX1+v555/X1772NZWWliorK8u/zfz58/Xkk0/6/y4tLdXhw4e1ceNGffDBByovL9e//du/qaSkZAgOEVbBXCYAgKsJ6nFo2x9/UP7c1q1btXz5ckmXH21+9tln9fHHHysjI0MrVqxQaWlpwL4ZGRlavny5vv/97/vX7d69W2VlZXr//feVmZmpNWvW6L777uv3gfA4dPjweDtMnT7e4+3Q6ZY2ZSbGEJoA4BoL9vd7UPO4hBKCC4aCFd/QDABWdl3ncQHCCU81AUDoI7gAf3Slp5oAAKGB4AL8Uc9TTX+Kp5oAILQQXIA/4qkmAAh9A5qADghXxbnpypuSZOpTTQCAvhFc0CsrPxI82NpTnNGWO2YAGC4ILvgMKz8SbOXaAQBXxxgXBLDyI8FWrh0A0D8EFwSw8iPBVq4dANA/BBcEsPIjwVauHQDQPwQXBLDyI8FWrh0A0D+8qwi9MvtFh4Nh5doBYLgJ9vebp4rQKys/Emzl2gEAV0ZXEQAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsAyCCwAAsIyggovb7VZubq7i4uI0btw43XHHHaqrqwvYpr6+XoWFhUpKSpLD4dCdd96ppqamfn/Hpk2bZLPZtHr16mBKAwAAw0BQwaW6ulolJSU6fPiwXn31VXV1damgoEBtbW2SpLa2NhUUFMhms6myslKHDh3SpUuXtGjRIvl8vqu2f/ToUf3rv/6rcnJyBnY0AAAgrI0IZuNXXnkl4O9nn31W48aNU21trfLy8nTo0CGdOXNGb7zxhhwOhyTpueee05gxY1RZWan8/Pw+2/700091991365lnntEPf/jDARwKAAAId4Ma4+L1eiVJCQkJkqTOzk7ZbDbZ7Xb/NqNGjVJERIQOHjx4xbZKSkr01a9+9Yrh5k91dnaqtbU1YAEAAOFtwMHF5/Np9erVmjt3rqZPny5JmjNnjmJiYrR27Vq1t7erra1NDz30kLq7u+XxePpsa9u2bTp+/Ljcbne/v9/tdsvpdPqXCRMmDPRQAACARQw4uJSUlOjUqVPatm2bf11SUpJ27NihXbt2KTY2Vk6nU+fPn9fMmTMVEdH7V509e1YPPvigfvGLX2jUqFH9/v6ysjJ5vV7/cvbs2YEeCgAAsIigxrj0WLlypXbv3q0DBw4oLS0t4LOCggLV19erpaVFI0aMUHx8vJKTkzVp0qRe26qtrVVzc7NmzpzpX9fd3a0DBw7oySefVGdnpyIjIz+zn91uD+iSAgAA4S+o4GIYhlatWqWKigpVVVUpMzOzz20TExMlSZWVlWpubtbtt9/e63bz58/XyZMnA9b97d/+rbKzs7V27dpeQwsAABieggouJSUlKi8v10svvaS4uDg1NjZKkpxOp6KjoyVJW7du1dSpU5WUlKSamho9+OCDKi0tVVZWlr+d+fPnq7CwUCtXrlRcXJx/jEyPmJgYjR079jPrAQDA8BZUcNmyZYsk6eabbw5Yv3XrVi1fvlySVFdXp7KyMn388cfKyMjQd77zHZWWlgZs39OVBAAAEAybYRiG2UUMhdbWVjmdTnm9Xv8cMgAAILQF+/vNu4oAAIBlEFwAAIBlEFwAAIBlEFyuMY+3Q6/Xt8jj7TC7FAAALG9AE9Chf7YfbVDZzpPyGVKETXIXzVBxbrrZZQEAYFnccblGPN4Of2iRJJ8hrd95ijsvAAAMAsHlGjnd0uYPLT26DUNnWtrNKQgAgDBAcLmKgY5RyUyMUYQtcF2kzaaMxNFDWB0AAMMLweUKth9t0NxNlfrGM0c0d1Olth9t6Pe+Kc5ouYtmKNJ2Ob1E2mzaWDRdKc7oa1UuAABhj5lz++DxdmjupsqA7p5Im00H190SVPjweDt0pqVdGYmjCS0AAPyZYH+/eaqoD1caoxJMAElxRg/LwOLxduh0S5syE2OG5fEDAK4Ngksfesao/PkdF8aoXB2PgQMArhXGuPSBMSoDw2PgAIBriTsuV1Ccm668KUmMUQnCUHWxAQDQG4LLVVh5jIoZ40zoYgMAXEt0FYWpwTzKPRh0sQEAriUehw5DQ/Uo92BroIsNAHA1PA6NkBhnYuUuNgBA6KKrKAzxugEAQLgiuIQhxpkAAMIVXUVhike5AQDhiOASxhhnAgAIN3QVAQAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAyyC4AAAAywgquLjdbuXm5iouLk7jxo3THXfcobq6uoBt6uvrVVhYqKSkJDkcDt15551qamoadLsAAABBBZfq6mqVlJTo8OHDevXVV9XV1aWCggK1tbVJktra2lRQUCCbzabKykodOnRIly5d0qJFi+Tz+Qbc7nDl8Xbo9foWebwdZpcCAEBIsBmGYQx059///vcaN26cqqurlZeXp3379mnhwoX65JNP5HA4JEler1djxozRvn37lJ+fP6B2+6O1tVVOp1Ner9f/3Va2/WiDynaelM+QImySu2iGinPTzS4LAIAhFezv96DGuHi9XklSQkKCJKmzs1M2m012u92/zahRoxQREaGDBw8OuN3edHZ2qrW1NWAJFx5vhz+0SJLPkNbvPMWdFwDAsDfg4OLz+bR69WrNnTtX06dPlyTNmTNHMTExWrt2rdrb29XW1qaHHnpI3d3d8ng8A263N263W06n079MmDBhoIcSck63tPlDS49uw9CZlnZzCgIAIEQMOLiUlJTo1KlT2rZtm39dUlKSduzYoV27dik2NlZOp1Pnz5/XzJkzFRHRv6/qrd3elJWVyev1+pezZ88O9FBCTmZijCJsgesibTZlJI42pyAAAELEiIHstHLlSu3evVsHDhxQWlpawGcFBQWqr69XS0uLRowYofj4eCUnJ2vSpEmDavfP2e32gC6pcJLijJa7aIbW7zylbsNQpM2mjUXTleKMNrs0AABMFVRwMQxDq1atUkVFhaqqqpSZmdnntomJiZKkyspKNTc36/bbbx+SdoeL4tx05U1J0pmWdmUkjia0AACgIINLSUmJysvL9dJLLykuLk6NjY2SJKfTqejoyz+sW7du1dSpU5WUlKSamho9+OCDKi0tVVZWlr+d+fPnq7CwUCtXrux3u8NRijOawAIAwJ8IKrhs2bJFknTzzTcHrN+6dauWL18uSaqrq1NZWZk+/vhjZWRk6Dvf+Y5KS0sDtu/pSgqmXQAAgEHN4xJKwm0eFwAAhoPrOo8LAADA9URwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAlkFwAQAAljGgt0OHop4JgFtbW02uBAAA9FfP73Z/J/IPm+By4cIFSdKECRNMrgQAAATrwoULcjqdV90ubN5V5PP5dO7cOcXFxclmsw1Zu62trZowYYLOnj3LO5CCwHkbGM5b8DhnA8N5GxjO28Bc6bwZhqELFy4oNTVVERFXH8ESNndcIiIilJaWds3adzgcXKQDwHkbGM5b8DhnA8N5GxjO28D0dd76c6elB4NzAQCAZRBcAACAZRBcrsJut+t73/ue7Ha72aVYCudtYDhvweOcDQznbWA4bwMzlOctbAbnAgCA8McdFwAAYBkEFwAAYBkEFwAAYBkEFwAAYBkEl6v42c9+poyMDI0aNUqzZ8/Wf/3Xf5ldUkj7/ve/L5vNFrBkZ2ebXVZIOXDggBYtWqTU1FTZbDb9+te/DvjcMAx997vfVUpKiqKjo5Wfn6/333/fnGJDyNXO2/Llyz9z7d12223mFBsi3G63cnNzFRcXp3HjxumOO+5QXV1dwDYXL15USUmJxo4dq9jYWC1ZskRNTU0mVRwa+nPebr755s9cbytWrDCp4tCwZcsW5eTk+CeZc7lc2rNnj//zobrWCC5XsH37dq1Zs0bf+973dPz4cd14441asGCBmpubzS4tpH3+85+Xx+PxLwcPHjS7pJDS1tamG2+8UT/72c96/fzRRx/VT3/6Uz399NM6cuSIYmJitGDBAl28ePE6VxparnbeJOm2224LuPZeeOGF61hh6KmurlZJSYkOHz6sV199VV1dXSooKFBbW5t/m9LSUu3atUs7duxQdXW1zp07p6KiIhOrNl9/zpsk3XfffQHX26OPPmpSxaEhLS1NmzZtUm1trY4dO6Z58+Zp8eLFeuuttyQN4bVmoE9f+tKXjJKSEv/f3d3dRmpqquF2u02sKrR973vfM2688Uazy7AMSUZFRYX/b5/PZyQnJxuPPfaYf9358+cNu91uvPDCCyZUGJr+/LwZhmEsW7bMWLx4sSn1WEVzc7MhyaiurjYM4/K1NXLkSGPHjh3+bd555x1DklFTU2NWmSHnz8+bYRjGTTfdZDz44IPmFWURY8aMMf793/99SK817rj04dKlS6qtrVV+fr5/XUREhPLz81VTU2NiZaHv/fffV2pqqiZNmqS7775bDQ0NZpdkGadPn1ZjY2PAded0OjV79myuu36oqqrSuHHjlJWVpQceeEB/+MMfzC4ppHi9XklSQkKCJKm2tlZdXV0B11t2drbS09O53v7En5+3Hr/4xS+UmJio6dOnq6ysTO3t7WaUF5K6u7u1bds2tbW1yeVyDem1FjYvWRxqLS0t6u7u1vjx4wPWjx8/Xu+++65JVYW+2bNn69lnn1VWVpY8Ho9+8IMf6K/+6q906tQpxcXFmV1eyGtsbJSkXq+7ns/Qu9tuu01FRUXKzMxUfX291q9fr4ULF6qmpkaRkZFml2c6n8+n1atXa+7cuZo+fbqky9dbVFSU4uPjA7blevt/vZ03SfrGN76hiRMnKjU1VW+++abWrl2ruro67dy508RqzXfy5Em5XC5dvHhRsbGxqqio0LRp03TixIkhu9YILhhSCxcu9P87JydHs2fP1sSJE/XLX/5S9957r4mVIdzddddd/n/PmDFDOTk5uuGGG1RVVaX58+ebWFloKCkp0alTpxhzFqS+ztv999/v//eMGTOUkpKi+fPnq76+XjfccMP1LjNkZGVl6cSJE/J6vXrxxRe1bNkyVVdXD+l30FXUh8TEREVGRn5mxHNTU5OSk5NNqsp64uPjNWXKFH3wwQdml2IJPdcW193gTZo0SYmJiVx7klauXKndu3frtddeU1pamn99cnKyLl26pPPnzwdsz/V2WV/nrTezZ8+WpGF/vUVFRWny5MmaNWuW3G63brzxRm3evHlIrzWCSx+ioqI0a9Ys7d+/37/O5/Np//79crlcJlZmLZ9++qnq6+uVkpJidimWkJmZqeTk5IDrrrW1VUeOHOG6C9L//u//6g9/+MOwvvYMw9DKlStVUVGhyspKZWZmBnw+a9YsjRw5MuB6q6urU0NDw7C+3q523npz4sQJSRrW11tvfD6fOjs7h/ZaG9rxw+Fl27Ztht1uN5599lnj7bffNu6//34jPj7eaGxsNLu0kPXtb3/bqKqqMk6fPm0cOnTIyM/PNxITE43m5mazSwsZFy5cMN544w3jjTfeMCQZP/nJT4w33njD+PDDDw3DMIxNmzYZ8fHxxksvvWS8+eabxuLFi43MzEyjo6PD5MrNdaXzduHCBeOhhx4yampqjNOnTxu//e1vjZkzZxqf+9znjIsXL5pdumkeeOABw+l0GlVVVYbH4/Ev7e3t/m1WrFhhpKenG5WVlcaxY8cMl8tluFwuE6s239XO2wcffGD84z/+o3Hs2DHj9OnTxksvvWRMmjTJyMvLM7lyc61bt86orq42Tp8+bbz55pvGunXrDJvNZuzbt88wjKG71gguV/HEE08Y6enpRlRUlPGlL33JOHz4sNklhbTi4mIjJSXFiIqKMv7iL/7CKC4uNj744AOzywopr732miHpM8uyZcsMw7j8SPSGDRuM8ePHG3a73Zg/f75RV1dnbtEh4Ernrb293SgoKDCSkpKMkSNHGhMnTjTuu+++Yf8/Gb2dL0nG1q1b/dt0dHQYf//3f2+MGTPGGD16tFFYWGh4PB7zig4BVztvDQ0NRl5enpGQkGDY7XZj8uTJxsMPP2x4vV5zCzfZ3/3d3xkTJ040oqKijKSkJGP+/Pn+0GIYQ3et2QzDMAZ4BwgAAOC6YowLAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwDIILAACwjP8DwZTpuNXJ2JwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "LbN8hA8WKFN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "inputDim = 1       # takes variable 'x' - 10 features\n",
        "outputDim = 1       # takes variable 'y'\n",
        "learningRate = 0.1\n",
        "epochs = 1500\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "##### For GPU #######\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
        "\n",
        "\n",
        "training_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Converting inputs and labels to Variable\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = Variable(torch.from_numpy(x).cuda())\n",
        "        labels = Variable(torch.from_numpy(y).cuda())\n",
        "    else:\n",
        "        inputs = Variable(torch.from_numpy(x))\n",
        "        labels = Variable(torch.from_numpy(y))\n",
        "\n",
        "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get output from the model, given the inputs\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # get loss for the predicted output\n",
        "    loss = criterion(outputs, labels)\n",
        "    # get gradients w.r.t to parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "    training_loss.append(loss.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kdnxHjKuKJLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "    if torch.cuda.is_available():\n",
        "        predicted = model(Variable(torch.from_numpy(x).cuda())).cpu().data.numpy()\n",
        "    else:\n",
        "        predicted = model(Variable(torch.from_numpy(x))).data.numpy()\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(x, y, 'go', label='True data', alpha=0.5)\n",
        "plt.plot(x, predicted, '--', label='Predictions', alpha=0.5)\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ljJqhv6oOYLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "# print the weight\n",
        "for param in model.parameters():\n",
        "  print(param.data)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JSG9ennYO72v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "1.   https://machinelearningmastery.com/building-a-logistic-regression-classifier-in-pytorch/\n",
        "2.   https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/\n",
        "3.   https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r9_BHa9IfJqt"
      }
    }
  ]
}